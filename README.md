# Readme for Retrograph

Environment: python 3.6

Please, follow these instructions to execute the experiments.

## 0 - Dependencies
```
pip install networkx
pip install tqdm
pip install waws
TODO add all dependencies
```

## 1 - Downloading project data
Step 1: GLUE data, Pretrained BERT model and relations
```
bash ./download_data_project.sh 
```

## 2 - Creating Random Walks

Step 2: Create the sequences of tokens using random walks generated by node2vec:
```
bash ./create_random_walks.sh 
```
It creates a file with the data: `randomwalks/random_walk_1.0_1.0_2_15.p`


## 3 - Generating the Corpus
Step 3: Create natural language text from the random walks:
```
bash ./generate_corpus.sh 
```
The generated corpus will be used as input for BERT + Adapters. It creates a file in TF format: `randomwalks/rw_corpus_1.0_1.0_2_15_nl.tf`


## 4 - Pretraining Adapter

Step 4: Pretrain the adapter using the RW corpus:
```
bash ./pretrain_adapter.sh 
```


## 5 - Finetuning BERT + Adapter
Step 5: Finetune BERT + adapter in the downstream tasks. To execute a grid search for the hyperparameters, execute the following command:
```
bash ./proc_finetuning_adapter_longer.sh
```


## 4 - GLUE Submission

Step1: (find best results from grid search)
fetcher.py -> helps you find the best model from a grid generated version of the model

Step2:
predictions_....sh

parse_prediction.py -> helps you create the right output file format, and you need to name the glue.zip submission folder in the right way as well.


## TODO:
1. CommonsenseQA:
- Preprocessor for CommonsenseQA
- Download CommonsenseQA dataset
- Evaluation scripts or standards?

github/jonathanherzig



<!-- EOF -->
